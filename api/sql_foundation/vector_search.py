"""
Vector Search Module - Semantic search using embeddings

This module provides:
1. Vector similarity search via Supabase RPC functions
2. Uses embeddings already generated by the extraction API
3. Integration with the wave-based SQL execution layer

For GPT lane queries where semantic understanding is needed.
The OpenAI key is in Render env vars - extraction API generates embeddings.
"""

import os
import time
import logging
import json
from typing import List, Dict, Any, Optional
from dataclasses import dataclass

import httpx

logger = logging.getLogger(__name__)

# Environment
SUPABASE_URL = os.environ.get("SUPABASE_URL", "https://vzsohavtuotocgrfkfyd.supabase.co")
SUPABASE_KEY = os.environ.get("SUPABASE_SERVICE_KEY", os.environ.get("SUPABASE_KEY", ""))


@dataclass
class VectorResult:
    """Result from vector search"""
    chunk_id: str
    content: str
    metadata: Dict
    similarity: float
    source_table: str = "graph_nodes"


class VectorSearchEngine:
    """
    Semantic vector search using pre-generated embeddings.

    The extraction API (on Render) generates embeddings using OpenAI.
    This module uses those embeddings to search via Supabase RPC functions:
    - hybrid_graph_search: searches graph_nodes
    - search_parts_vector: searches pms_parts
    """

    def __init__(
        self,
        supabase_url: str = None,
        supabase_key: str = None
    ):
        self.supabase_url = supabase_url or SUPABASE_URL
        self.supabase_key = supabase_key or SUPABASE_KEY
        self.client = httpx.Client(timeout=30.0)

    def is_available(self) -> bool:
        """Vector search is available if we have Supabase credentials"""
        return bool(self.supabase_key)

    def search_with_embedding(
        self,
        embedding: List[float],
        yacht_id: str,
        limit: int = 10
    ) -> Dict[str, Any]:
        """
        Search using pre-generated embedding from extraction API.

        Uses working RPC functions:
        - hybrid_graph_search for graph nodes (equipment, systems)
        - search_parts_vector for parts
        """
        start = time.time()
        results = []
        errors = []

        headers = {
            "apikey": self.supabase_key,
            "Authorization": f"Bearer {self.supabase_key}",
            "Content-Type": "application/json"
        }

        # 1. Search graph nodes via hybrid_graph_search
        try:
            resp = self.client.post(
                f"{self.supabase_url}/rest/v1/rpc/hybrid_graph_search",
                headers=headers,
                json={
                    "p_yacht_id": yacht_id,
                    "p_query_embedding": embedding,
                    "p_limit": limit
                }
            )

            if resp.status_code == 200:
                for row in resp.json():
                    results.append(VectorResult(
                        chunk_id=row.get("node_id", ""),
                        content=row.get("label", ""),
                        metadata={"type": row.get("node_type"), "properties": row.get("properties", {})},
                        similarity=row.get("similarity", 0.0),
                        source_table="graph_nodes"
                    ))
            else:
                errors.append(f"hybrid_graph_search: {resp.text[:100]}")

        except Exception as e:
            errors.append(f"hybrid_graph_search: {str(e)}")

        # 2. Search parts via search_parts_vector
        try:
            resp = self.client.post(
                f"{self.supabase_url}/rest/v1/rpc/search_parts_vector",
                headers=headers,
                json={
                    "p_yacht_id": yacht_id,
                    "p_query_embedding": embedding,
                    "p_limit": limit
                }
            )

            if resp.status_code == 200:
                for row in resp.json():
                    results.append(VectorResult(
                        chunk_id=row.get("id", ""),
                        content=row.get("name", row.get("part_number", "")),
                        metadata=row,
                        similarity=row.get("similarity", 0.0),
                        source_table="pms_parts"
                    ))

        except Exception as e:
            errors.append(f"search_parts_vector: {str(e)}")

        # Sort by similarity
        results.sort(key=lambda x: x.similarity, reverse=True)

        elapsed = (time.time() - start) * 1000

        return {
            "results": results[:limit],
            "method": "vector_rpc",
            "query_time_ms": elapsed,
            "error": "; ".join(errors) if errors else None,
            "sources": ["graph_nodes", "pms_parts"]
        }

    def _text_search_fallback(
        self,
        query: str,
        yacht_id: str,
        limit: int
    ) -> tuple:
        """Fallback to ILIKE text search on document content"""
        headers = {
            "apikey": self.supabase_key,
            "Authorization": f"Bearer {self.supabase_key}",
        }

        try:
            terms = query.lower().split()
            if not terms:
                return [], "Empty query"

            search_term = terms[0]

            resp = self.client.get(
                f"{self.supabase_url}/rest/v1/search_document_chunks",
                params={
                    "yacht_id": f"eq.{yacht_id}",
                    "content": f"ilike.*{search_term}*",
                    "select": "id,content,metadata",
                    "limit": str(limit)
                },
                headers=headers
            )

            if resp.status_code == 200:
                data = resp.json()
                results = [
                    VectorResult(
                        chunk_id=row.get("id", ""),
                        content=row.get("content", "")[:500],
                        metadata=row.get("metadata", {}),
                        similarity=0.5,
                        source_table="search_document_chunks"
                    )
                    for row in data
                ]
                return results, None
            else:
                return [], f"Text search error: {resp.text[:200]}"

        except Exception as e:
            return [], str(e)


def execute_vector_search(
    embedding: List[float],
    yacht_id: str,
    limit: int = 10,
    query_text: str = ""
) -> Dict[str, Any]:
    """
    Execute vector search using pre-generated embedding.

    The embedding should come from the extraction API (which uses OpenAI).
    This function uses Supabase RPC functions to search:
    - hybrid_graph_search: graph nodes (equipment, systems)
    - search_parts_vector: parts catalog

    Args:
        embedding: 1536-dim embedding from text-embedding-3-small
        yacht_id: Yacht ID filter
        limit: Max results
        query_text: Original query (for text fallback if no embedding)

    Returns:
        Dict with results, method, timing, and errors
    """
    engine = VectorSearchEngine()

    if not engine.is_available():
        return {
            "results": [],
            "method": "unavailable",
            "error": "Supabase credentials not available",
            "query_time_ms": 0
        }

    # If no embedding provided, use text fallback
    if not embedding or len(embedding) < 100:
        if query_text:
            results, error = engine._text_search_fallback(query_text, yacht_id, limit)
            return {
                "results": results,
                "method": "text_fallback",
                "query_time_ms": 0,
                "error": error
            }
        else:
            return {
                "results": [],
                "method": "no_embedding",
                "error": "No embedding provided and no query text for fallback",
                "query_time_ms": 0
            }

    # Use vector search with the provided embedding
    return engine.search_with_embedding(embedding, yacht_id, limit)


# =============================================================================
# TEST
# =============================================================================

if __name__ == "__main__":
    yacht_id = "85fe1119-b04c-41ac-80f1-829d23322598"

    print("=== Vector Search Test ===")

    # Test with placeholder embedding
    test_embedding = [0.01] * 1536

    result = execute_vector_search(
        embedding=test_embedding,
        yacht_id=yacht_id,
        limit=5
    )

    print(f"Method: {result['method']}")
    print(f"Time: {result.get('query_time_ms', 0):.0f}ms")
    print(f"Results: {len(result['results'])}")

    if result.get('error'):
        print(f"Error: {result['error']}")

    for r in result['results'][:3]:
        print(f"\n  - {r.content[:100]}...")
        print(f"    similarity: {r.similarity:.2f}")
