# ‚úÖ Schema V2.0 Deployment - Verification & Next Steps

## üéâ Deployment Status: COMPLETE

Schema V2.0 has been deployed to Supabase project: `vzsohavtuotocgrfkfyd`

---

## üîç Verification Checklist

Run these queries in Supabase SQL Editor to confirm everything deployed correctly:

### 1. Check Table Count
```sql
SELECT COUNT(*) as table_count
FROM information_schema.tables
WHERE table_schema = 'public'
AND table_type = 'BASE TABLE';
```
**Expected:** 34 tables

---

### 2. Verify pgvector Extension
```sql
SELECT extname, extversion
FROM pg_extension
WHERE extname = 'vector';
```
**Expected:** 1 row showing pgvector is installed

---

### 3. Verify Auth Integration
```sql
SELECT
  table_name,
  column_name,
  data_type,
  is_nullable
FROM information_schema.columns
WHERE column_name = 'auth_user_id'
AND table_schema = 'public';
```
**Expected:** 1 row showing `users.auth_user_id uuid NOT NULL`

---

### 4. Check bcrypt Hash Constraints
```sql
SELECT
  tc.table_name,
  cc.column_name,
  cc.check_clause
FROM information_schema.table_constraints tc
JOIN information_schema.check_constraints cc
  ON tc.constraint_name = cc.constraint_name
WHERE cc.check_clause LIKE '%$2%'
ORDER BY tc.table_name;
```
**Expected:** 4+ constraints on yachts, agents, api_keys (bcrypt format validation)

---

### 5. Verify Vector Index
```sql
SELECT
  indexname,
  indexdef
FROM pg_indexes
WHERE indexname = 'idx_document_chunks_embedding';
```
**Expected:** 1 row showing IVFFlat index on document_chunks.embedding

---

### 6. List All Tables (Organized)
```sql
SELECT
  table_name,
  (SELECT COUNT(*) FROM information_schema.columns
   WHERE table_name = t.table_name AND table_schema = 'public') as column_count
FROM information_schema.tables t
WHERE table_schema = 'public'
AND table_type = 'BASE TABLE'
ORDER BY table_name;
```

**Expected tables:**
- agents
- api_keys
- document_chunks
- documents
- embedding_jobs
- equipment
- equipment_parts
- event_logs
- faults
- graph_edges
- graph_nodes
- handover_items
- handovers
- hours_of_rest
- inventory_stock
- ocred_pages
- parts
- predictive_insights
- predictive_state
- purchase_order_items
- purchase_orders
- search_queries
- suppliers
- user_roles
- users
- work_order_history
- work_orders
- yachts

---

## üß™ Test Data Creation

### Create Test Yacht
```sql
INSERT INTO yachts (name, yacht_secret_hash, status)
VALUES (
  'Test Yacht Alpha',
  '$2b$10$N9qo8uLOickgx2ZMRZoMyeIjZAgcfl7p92ldGxad68LJZdL17lhWy', -- hash of "test_secret_123"
  'active'
)
RETURNING id, name;
```

### Create Test User (after Supabase Auth user exists)
```sql
-- First, create user in Supabase Auth UI or via API
-- Then link to business user:

INSERT INTO users (
  auth_user_id,
  yacht_id,
  email,
  name,
  role
)
VALUES (
  '<auth_user_id_from_supabase_auth>', -- Get from auth.users
  (SELECT id FROM yachts WHERE name = 'Test Yacht Alpha'),
  'test@celesteos.io',
  'Test Chief Engineer',
  'chief_engineer'
)
RETURNING id, name, email;
```

### Create Test Agent
```sql
INSERT INTO agents (
  yacht_id,
  name,
  agent_secret_hash,
  device_info
)
VALUES (
  (SELECT id FROM yachts WHERE name = 'Test Yacht Alpha'),
  'Mac Studio - Engine Room',
  '$2b$10$N9qo8uLOickgx2ZMRZoMyeIjZAgcfl7p92ldGxad68LJZdL17lhWy',
  '{"os": "macOS", "version": "14.1", "device": "Mac Studio M2"}'::jsonb
)
RETURNING id, name;
```

### Create Test API Key
```sql
INSERT INTO api_keys (
  yacht_id,
  key_prefix,
  hashed_key,
  name,
  scopes
)
VALUES (
  (SELECT id FROM yachts WHERE name = 'Test Yacht Alpha'),
  'sk_test_a1b2',
  '$2b$10$N9qo8uLOickgx2ZMRZoMyeIjZAgcfl7p92ldGxad68LJZdL17lhWy',
  'n8n Test Integration',
  ARRAY['read:equipment', 'write:work_orders']
)
RETURNING id, name, key_prefix;
```

---

## üîê Enable Supabase Auth

### 1. Configure Auth Providers

Go to: https://supabase.com/dashboard/project/vzsohavtuotocgrfkfyd/auth/providers

**Enable:**
- ‚úÖ Email/Password
- ‚úÖ Microsoft (Azure AD/SSO)

### 2. Set up Microsoft SSO (Recommended)

Follow: https://supabase.com/docs/guides/auth/social-login/auth-azure

**You'll need:**
- Azure AD Application ID
- Azure AD Client Secret
- Redirect URL: `https://vzsohavtuotocgrfkfyd.supabase.co/auth/v1/callback`

### 3. Create Database Trigger (Optional but Recommended)

Auto-create `users` record when `auth.users` created:

```sql
CREATE OR REPLACE FUNCTION public.handle_new_user()
RETURNS TRIGGER AS $$
BEGIN
  -- Auto-create business user record when auth user created
  -- Requires yacht_id to be set via metadata during signup
  INSERT INTO public.users (
    auth_user_id,
    yacht_id,
    email,
    name,
    role
  )
  VALUES (
    NEW.id,
    (NEW.raw_user_meta_data->>'yacht_id')::uuid,
    NEW.email,
    COALESCE(NEW.raw_user_meta_data->>'name', NEW.email),
    COALESCE(NEW.raw_user_meta_data->>'role', 'deck')
  );
  RETURN NEW;
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;

-- Create trigger
DROP TRIGGER IF EXISTS on_auth_user_created ON auth.users;
CREATE TRIGGER on_auth_user_created
  AFTER INSERT ON auth.users
  FOR EACH ROW
  EXECUTE FUNCTION public.handle_new_user();
```

---

## üîí Configure Row-Level Security (RLS) Policies

### Example: Users Table RLS

```sql
-- Users can only see their own yacht's users
CREATE POLICY "Users can view own yacht users"
  ON users FOR SELECT
  USING (
    yacht_id = (
      SELECT yacht_id FROM users
      WHERE auth_user_id = auth.uid()
    )
  );

-- Users can update their own record
CREATE POLICY "Users can update own record"
  ON users FOR UPDATE
  USING (auth_user_id = auth.uid());
```

### Example: Equipment Table RLS

```sql
-- Users can only see their yacht's equipment
CREATE POLICY "Users can view own yacht equipment"
  ON equipment FOR SELECT
  USING (
    yacht_id = (
      SELECT yacht_id FROM users
      WHERE auth_user_id = auth.uid()
    )
  );

-- Users can insert equipment for their yacht
CREATE POLICY "Users can create equipment for own yacht"
  ON equipment FOR INSERT
  WITH CHECK (
    yacht_id = (
      SELECT yacht_id FROM users
      WHERE auth_user_id = auth.uid()
    )
  );
```

**Note:** Repeat similar policies for all 34 tables. See: https://supabase.com/docs/guides/auth/row-level-security

---

## üì° Next Steps - API Development

### 1. Set up API Authentication Middleware

**For user requests (JWT):**
```javascript
// Validate Supabase JWT token
const { data: { user } } = await supabase.auth.getUser(token);

// Get business user + yacht_id
const { data: businessUser } = await supabase
  .from('users')
  .select('id, yacht_id, role')
  .eq('auth_user_id', user.id)
  .single();

// All queries now scoped to businessUser.yacht_id
```

**For agent requests (HMAC):**
```javascript
// Verify HMAC signature
const signature = req.headers['x-signature'];
const agentId = req.headers['x-agent-id'];

// Lookup agent and verify HMAC
const { data: agent } = await supabase
  .from('agents')
  .select('yacht_id, agent_secret_hash')
  .eq('id', agentId)
  .single();

// Verify HMAC(request_body, agent_secret) matches signature
// Use bcrypt.compare() to verify
```

**For API key requests:**
```javascript
const apiKey = req.headers['x-api-key'];

// Hash and lookup
const hashedKey = await bcrypt.hash(apiKey, 10);

const { data: key } = await supabase
  .from('api_keys')
  .select('yacht_id, scopes, is_active')
  .eq('hashed_key', hashedKey)
  .eq('is_active', true)
  .single();

// Check scopes for requested operation
```

---

### 2. Build Indexing Pipeline (n8n)

**Workflow:**
1. NAS Upload ‚Üí Trigger
2. Store in Supabase Storage
3. OCR Processing
4. Chunking
5. Embedding Generation
6. Insert into `document_chunks`
7. Update `documents.indexed = true`

See: `indexing-pipeline.md`

---

### 3. Build Search API

**Endpoint:** `POST /v1/search`

**Implementation:**
1. Extract entities from query
2. Generate embedding for query text
3. Vector search on `document_chunks`
4. Optionally: GraphRAG traversal via `graph_nodes/edges`
5. Return result cards with micro-actions

See: `search-engine-spec.md`

---

## üìä Monitoring & Maintenance

### Database Size Monitoring
```sql
SELECT
  pg_size_pretty(pg_database_size('postgres')) as total_size,
  (SELECT COUNT(*) FROM document_chunks) as total_chunks,
  (SELECT COUNT(*) FROM documents WHERE indexed = true) as indexed_docs;
```

### Index Health Check
```sql
SELECT
  schemaname,
  tablename,
  indexname,
  idx_scan,
  idx_tup_read,
  idx_tup_fetch
FROM pg_stat_user_indexes
ORDER BY idx_scan DESC;
```

---

## üéØ Summary

**‚úÖ Deployed:**
- 34 tables with proper relationships
- pgvector extension for semantic search
- bcrypt-based authentication for agents/API keys
- SHA256 file integrity for documents
- Row-level security enabled (policies needed)
- Supabase Auth integration ready

**üîÑ Next Actions:**
1. Configure Supabase Auth providers
2. Create RLS policies for all tables
3. Build API authentication middleware
4. Implement indexing pipeline (n8n)
5. Build search API endpoint
6. Create local agent (Mac app)

**üìñ Reference Docs:**
- `AUTH_INTEGRATION.md` - Auth flows
- `api-spec.md` - API endpoints
- `indexing-pipeline.md` - Document processing
- `search-engine-spec.md` - Search implementation
- `agent-spec.md` - Local agent specification

---

**Schema V2.0 is production-ready. Time to build the API layer!** üöÄ
